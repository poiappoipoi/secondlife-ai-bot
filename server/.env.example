# Server Configuration
PORT=3000

# AI Provider (xai | ollama)
AI_PROVIDER=xai
AI_MAX_TOKENS=300
AI_TIMEOUT_MS=30000

# X.AI (Grok) Configuration
XAI_API_KEY=your-xai-api-key-here
XAI_MODEL=grok-4-1-fast-non-reasoning

# Ollama Configuration (local LLM)
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=huihui_ai/qwen2.5-abliterate

# Rate Limiting
RATE_LIMIT_MAX=40
RATE_LIMIT_WINDOW_MS=3600000

# Conversation Settings
INACTIVITY_TIMEOUT_MS=3600000
CONVERSATION_MAX_HISTORY_MESSAGES=50

# Context Budget Management
CONTEXT_BUDGET_ENABLED=false
CONTEXT_MAX_TOKENS=8000
CONTEXT_SYSTEM_PROMPT_MAX_PERCENT=80

# Persona Settings
PERSONA_FILE=cat-maid.md
# PERSONAS_DIR=./personas

# Logging
LOG_LEVEL=INFO
LOG_TIMEZONE=UTC
